{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aaron-anayst/Twitter-Data-Analysis/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwT-iVMYKaVR"
      },
      "source": [
        "# Table of Contents\n",
        "0. [Introduction](#introduction)\n",
        "1. [pandas](#Pandas)\n",
        "2. [Matplotlib](#Matplotlib)\n",
        "3. [sklearn](#sklearn)\n",
        "4. [Modeling](#Modeling)\n",
        "5. [Deployment](#Deployment)\n",
        "6. [References](#References)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amqbYnAuKaVV"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "## Task 2 Steps\n",
        "5. ML training and validation - a code base to train topic modelling and sentiment analysis models.\n",
        "6. Deployment - a code base to make and deploy dashboard expose trained models. \n",
        "7. Model performance analyser - to integrate MLWatcher or something similar to monitor model performance at prediction time. \n",
        "8. A data drift or model underperformance trigger mechanism that identifies and shows an alert when model performance is below threshold or incoming data is drifted from the data used to train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJVcDKLwKaVV"
      },
      "source": [
        "## Data Gathering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqjqTxnIKaVW"
      },
      "source": [
        "### Downloading & extracting data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2sKOsmUMKaVW",
        "outputId": "1d2f5b5e-8094-4008-a17f-ca7c7679b612",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=9bb7440ce4b4de24c686059b4eebfd4c5f0a89551e9be2897515c0dc6b1c13fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FdB0PNzHKaVX",
        "outputId": "24aa8e6d-10e8-4f0c-a6ff-8de472f96b44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-27 08:45:13--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  15.9MB/s    in 6.8s    \n",
            "\n",
            "2022-04-27 08:45:20 (11.8 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3OyqLwoqKaVY",
        "outputId": "664c9dfc-f2e9-498d-98fb-430142c7619d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  16.1M      0  0:00:04  0:00:04 --:--:-- 16.4M\n"
          ]
        }
      ],
      "source": [
        "!curl \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\" -o aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nk8OMM-AKaVY"
      },
      "outputs": [],
      "source": [
        "!tar -xzf \"aclImdb_v1.tar.gz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lYH5uHRDKaVZ",
        "outputId": "976b7af8-dc94-4c8a-8522-1b3c096dfe8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 84125825 bytes (81 MiB)\n",
            "\n",
            "Extracting archive: aclImdb_v1.tar.gz\n",
            "--\n",
            "Path = aclImdb_v1.tar.gz\n",
            "Type = gzip\n",
            "Headers Size = 10\n",
            "\n",
            "  0% - aclImdb_v1.tar\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% - aclImdb_v1.tar\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% - aclImdb_v1.tar\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% - aclImdb_v1.tar\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% - aclImdb_v1.tar\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% - aclImdb_v1.tar\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% - aclImdb_v1.tar\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% - aclImdb_v1.tar\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% - aclImdb_v1.tar\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% - aclImdb_v1.tar\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% - aclImdb_v1.tar\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% - aclImdb_v1.tar\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% - aclImdb_v1.tar\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% - aclImdb_v1.tar\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% - aclImdb_v1.tar\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% - aclImdb_v1.tar\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Size:       298168320\n",
            "Compressed: 84125825\n"
          ]
        }
      ],
      "source": [
        "!7z x aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "i59v_ePvKaVa",
        "outputId": "fbfededc-ef6e-4d29-a902-aea35b72d3f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 373356\n",
            "drwxr-xr-x 1 root root      4096 Apr 27 08:45 .\n",
            "drwxr-xr-x 1 root root      4096 Apr 27 08:44 ..\n",
            "drwxr-xr-x 4 7297 1000      4096 Jun 26  2011 aclImdb\n",
            "-rw-r--r-- 1 root root 298168320 Jun 26  2011 aclImdb_v1.tar\n",
            "-rw-r--r-- 1 root root  84125825 Apr 27 08:45 aclImdb_v1.tar.gz\n",
            "drwxr-xr-x 4 root root      4096 Apr 25 13:45 .config\n",
            "drwxr-xr-x 1 root root      4096 Apr 25 13:46 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -la"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mM-Xmr0eKaVa",
        "outputId": "3a5c572c-0656-449e-f7a6-e13c70f07f47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imdbEr.txt  imdb.vocab\tREADME\ttest  train\n"
          ]
        }
      ],
      "source": [
        "!ls aclImdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nYiDi2OLKaVb",
        "outputId": "d597f63c-ab3f-4536-ea04-46ad409a48aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeledBow.feat  pos\tunsupBow.feat  urls_pos.txt\n",
            "neg\t\t unsup\turls_neg.txt   urls_unsup.txt\n"
          ]
        }
      ],
      "source": [
        "!ls aclImdb/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SwoX82ytKaVb",
        "outputId": "ae3c311c-1172-4462-9710-9c4ab23f8132",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeledBow.feat  neg  pos  urls_neg.txt  urls_pos.txt\n"
          ]
        }
      ],
      "source": [
        "!ls aclImdb/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DP1m78jtKaVb",
        "outputId": "1e1f0301-7ccf-4761-b8f3-2dedc1e48247",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0490972013402\n",
            "0.201363575849\n",
            "0.0333946807184\n",
            "0.099837669572\n",
            "-0.0790210365788\n",
            "0.188660139871\n",
            "0.00712569582356\n",
            "0.109215821589\n",
            "-0.154986397986\n",
            "-0.222690363917\n"
          ]
        }
      ],
      "source": [
        "!head -10 aclImdb/imdbEr.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jL_YrfjNKaVc",
        "outputId": "b01cac39-8871-4ca1-eaaa-47e9352a5077",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the\n",
            "and\n",
            "a\n",
            "of\n",
            "to\n",
            "is\n",
            "it\n",
            "in\n",
            "i\n",
            "this\n"
          ]
        }
      ],
      "source": [
        "!head -10 aclImdb/imdb.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xvYT4wsoKaVc",
        "outputId": "e7ab50b2-0e49-421f-f733-91d256314abe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large Movie Review Dataset v1.0\n",
            "\n",
            "Overview\n",
            "\n",
            "This dataset contains movie reviews along with their associated binary\n",
            "sentiment polarity labels. It is intended to serve as a benchmark for\n",
            "sentiment classification. This document outlines how the dataset was\n",
            "gathered, and how to use the files provided. \n",
            "\n",
            "Dataset \n",
            "\n",
            "The core dataset contains 50,000 reviews split evenly into 25k train\n",
            "and 25k test sets. The overall distribution of labels is balanced (25k\n",
            "pos and 25k neg). We also include an additional 50,000 unlabeled\n",
            "documents for unsupervised learning. \n",
            "\n",
            "In the entire collection, no more than 30 reviews are allowed for any\n",
            "given movie because reviews for the same movie tend to have correlated\n",
            "ratings. Further, the train and test sets contain a disjoint set of\n",
            "movies, so no significant performance is obtained by memorizing\n",
            "movie-unique terms and their associated with observed labels.  In the\n",
            "labeled train/test sets, a negative review has a score <= 4 out of 10,\n",
            "and a positive review has a score >= 7 out of 10. Thus reviews with\n",
            "more neutral ratings are not included in the train/test sets. In the\n",
            "unsupervised set, reviews of any rating are included and there are an\n",
            "even number of reviews > 5 and <= 5.\n",
            "\n",
            "Files\n",
            "\n",
            "There are two top-level directories [train/, test/] corresponding to\n",
            "the training and test sets. Each contains [pos/, neg/] directories for\n",
            "the reviews with binary labels positive and negative. Within these\n",
            "directories, reviews are stored in text files named following the\n",
            "convention [[id]_[rating].txt] where [id] is a unique id and [rating] is\n",
            "the star rating for that review on a 1-10 scale. For example, the file\n",
            "[test/pos/200_8.txt] is the text for a positive-labeled test set\n",
            "example with unique id 200 and star rating 8/10 from IMDb. The\n",
            "[train/unsup/] directory has 0 for all ratings because the ratings are\n",
            "omitted for this portion of the dataset.\n",
            "\n",
            "We also include the IMDb URLs for each review in a separate\n",
            "[urls_[pos, neg, unsup].txt] file. A review with unique id 200 will\n",
            "have its URL on line 200 of this file. Due the ever-changing IMDb, we\n",
            "are unable to link directly to the review, but only to the movie's\n",
            "review page.\n",
            "\n",
            "In addition to the review text files, we include already-tokenized bag\n",
            "of words (BoW) features that were used in our experiments. These \n",
            "are stored in .feat files in the train/test directories. Each .feat\n",
            "file is in LIBSVM format, an ascii sparse-vector format for labeled\n",
            "data.  The feature indices in these files start from 0, and the text\n",
            "tokens corresponding to a feature index is found in [imdb.vocab]. So a\n",
            "line with 0:7 in a .feat file means the first word in [imdb.vocab]\n",
            "(the) appears 7 times in that review.\n",
            "\n",
            "LIBSVM page for details on .feat file format:\n",
            "http://www.csie.ntu.edu.tw/~cjlin/libsvm/\n",
            "\n",
            "We also include [imdbEr.txt] which contains the expected rating for\n",
            "each token in [imdb.vocab] as computed by (Potts, 2011). The expected\n",
            "rating is a good way to get a sense for the average polarity of a word\n",
            "in the dataset.\n",
            "\n",
            "Citing the dataset\n",
            "\n",
            "When using this dataset please cite our ACL 2011 paper which\n",
            "introduces it. This paper also contains classification results which\n",
            "you may want to compare against.\n",
            "\n",
            "\n",
            "@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
            "  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
            "  title     = {Learning Word Vectors for Sentiment Analysis},\n",
            "  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
            "  month     = {June},\n",
            "  year      = {2011},\n",
            "  address   = {Portland, Oregon, USA},\n",
            "  publisher = {Association for Computational Linguistics},\n",
            "  pages     = {142--150},\n",
            "  url       = {http://www.aclweb.org/anthology/P11-1015}\n",
            "}\n",
            "\n",
            "References\n",
            "\n",
            "Potts, Christopher. 2011. On the negativity of negation. In Nan Li and\n",
            "David Lutz, eds., Proceedings of Semantics and Linguistic Theory 20,\n",
            "636-659.\n",
            "\n",
            "Contact\n",
            "\n",
            "For questions/comments/corrections please contact Andrew Maas\n",
            "amaas@cs.stanford.edu\n"
          ]
        }
      ],
      "source": [
        "!cat aclImdb/README"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpsAFRo1KaVc"
      },
      "source": [
        "## Environment Setup\n",
        "\n",
        "* Download Week 0 Tuesday folder onto your local filesystem (or wherever you're working)\n",
        "* Create folders you will later need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "beB42WTsKaVc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "!mkdir 'csv' \n",
        "!mkdir 'data_preprocessors' \n",
        "!mkdir 'vectorized_data' \n",
        "!mkdir 'classifiers'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AGRgEzklKaVd",
        "outputId": "1ed9ba8a-f287-4e7f-b6b0-2dbd0199719d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘csv’: File exists\n",
            "mkdir: cannot create directory ‘data_preprocessors’: File exists\n",
            "mkdir: cannot create directory ‘vectorized_data’: File exists\n",
            "mkdir: cannot create directory ‘classifiers’: File exists\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!mkdir csv \n",
        "!mkdir data_preprocessors \n",
        "!mkdir vectorized_data \n",
        "!mkdir classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nOxUj22xKaVd"
      },
      "outputs": [],
      "source": [
        "!mkdir -p csv data_preprocessors vectorized_data classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMK5fZPcKaVd"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pyqhPRr4KaVd"
      },
      "outputs": [],
      "source": [
        "# pandas library and other Python modules\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import re\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from random import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3Vbs0KZHKaVd"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "x7Cww_P8KaVe"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "from joblib import dump, load # used for saving and loading sklearn objects\n",
        "from scipy.sparse import save_npz, load_npz # used for saving and loading sparse matrices\n",
        "from scipy.stats import uniform\n",
        "from scipy.sparse import csr_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NapuJrPLKaVe"
      },
      "source": [
        "* <b>joblib</b>: In the specific case of scikit-learn, it may be better to use joblib’s replacement of pickle (dump & load), which is more efficient on objects that carry large numpy arrays internally as is often the case for fitted scikit-learn estimators, but can only pickle to the disk and not to a string:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avYlFQb-KaVe"
      },
      "source": [
        "# pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezn346MpKaVe"
      },
      "source": [
        "Pandas is a python package for data query and analysis. It is well known for its versatility in reading numerous types of data file. It also allows for simple data munging and visualization.\n",
        "\n",
        "https://pandas.pydata.org/\n",
        "\n",
        "https://pandas.pydata.org/docs/getting_started/index.html\n",
        "\n",
        "https://pandas.pydata.org/docs/getting_started/intro_tutorials/\n",
        "\n",
        "https://pandas.pydata.org/docs/reference/index.html\n",
        "\n",
        "<b> Pandas is heavily dependent on numpy. It borrows its philosophy from R dataframes. </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEoTS4O-KaVe"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "w2i8LtZhKaVf"
      },
      "outputs": [],
      "source": [
        "def create_data_frame(folder: str) -> pd.DataFrame:\n",
        "    '''\n",
        "    folder - the root folder of train or test dataset\n",
        "    Returns: a DataFrame with the combined data from the input folder\n",
        "    '''\n",
        "    pos_folder = f'{folder}/pos' # positive reviews\n",
        "    neg_folder = f'{folder}/neg' # negative reviews\n",
        "    \n",
        "    def get_files(fld: str) -> list:\n",
        "        '''\n",
        "        fld - positive or negative reviews folder\n",
        "        Returns: a list with all files in input folder\n",
        "        '''\n",
        "        return [join(fld, f) for f in listdir(fld) if isfile(join(fld, f))]\n",
        "    \n",
        "    def append_files_data(data_list: list, files: list, label: int) -> None:\n",
        "        '''\n",
        "        Appends to 'data_list' tuples of form (file content, label)\n",
        "        for each file in 'files' input list\n",
        "        '''\n",
        "        for file_path in files:\n",
        "            with open(file_path, 'r') as f:\n",
        "                text = f.read()\n",
        "                data_list.append((text, label))\n",
        "    \n",
        "    pos_files = get_files(pos_folder)\n",
        "    neg_files = get_files(neg_folder)\n",
        "    \n",
        "    data_list = []\n",
        "    append_files_data(data_list, pos_files, 1)\n",
        "    append_files_data(data_list, neg_files, 0)\n",
        "    shuffle(data_list)\n",
        "    \n",
        "    text, label = tuple(zip(*data_list))\n",
        "    # replacing line breaks with spaces\n",
        "    text = list(map(lambda txt: re.sub('(<br\\s*/?>)+', ' ', txt), text))\n",
        "    \n",
        "    return pd.DataFrame({'text': text, 'label': label})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LzIg41_iKaVf",
        "outputId": "d1c1fcc2-ffd2-4d9d-d76b-81c45b0857c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.58 s, sys: 719 ms, total: 6.3 s\n",
            "Wall time: 6.33 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "imdb_train = create_data_frame('aclImdb/train')\n",
        "imdb_test = create_data_frame('aclImdb/test')\n",
        "\n",
        "imdb_train.to_csv('csv/imdb_train.csv', index=False)\n",
        "imdb_test.to_csv('csv/imdb_test.csv', index=False)\n",
        "\n",
        "imdb_train = pd.read_csv('csv/imdb_train.csv')\n",
        "imdb_test = pd.read_csv('csv/imdb_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "I6Dxo1I2KaVf",
        "outputId": "7479cef1-b960-46b0-d661-602be2cef926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  What's wrong with this film? Many, many things...      0\n",
              "1  it is of course very nice to see improvements ...      0\n",
              "2  LES CONVOYEURS ATTENDENT was the first film I ...      1\n",
              "3  I heard and read many praising things about \"M...      0\n",
              "4  If you were ever sad for not being able to get...      1\n",
              "5  As an old white housewife I can still apprecia...      1\n",
              "6  I am glad being able to say almost only positi...      1\n",
              "7  DO NOT WATCH THIS MOVIE IF YOU LOVED THE CLASS...      0\n",
              "8  Lisa Baumer (Ida Galli) is the adulteress wife...      1\n",
              "9  Sometimes a movie is so comprehensively awful ...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11f01e46-08dd-4517-abc1-805dd7398907\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What's wrong with this film? Many, many things...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>it is of course very nice to see improvements ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LES CONVOYEURS ATTENDENT was the first film I ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I heard and read many praising things about \"M...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>If you were ever sad for not being able to get...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>As an old white housewife I can still apprecia...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I am glad being able to say almost only positi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>DO NOT WATCH THIS MOVIE IF YOU LOVED THE CLASS...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Lisa Baumer (Ida Galli) is the adulteress wife...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sometimes a movie is so comprehensively awful ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11f01e46-08dd-4517-abc1-805dd7398907')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11f01e46-08dd-4517-abc1-805dd7398907 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11f01e46-08dd-4517-abc1-805dd7398907');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "imdb_train.head(n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Nv6dyT7vKaVg",
        "outputId": "6d83b0aa-0d88-44c2-9a88-815211ca4431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  Although Flatliners is 15 years old, tonight w...      1\n",
              "1  This is a total piece of crap. It is an insult...      0\n",
              "2  ...un-funny and un-entertaining, possibly the ...      0\n",
              "3  It was high time a movie about the situation i...      1\n",
              "4  My Caddy Limo was destroyed!!! Well, I had one...      0\n",
              "5  Watching this on Comcast On-Demand. Every time...      1\n",
              "6  This is a cult film for many reasons. First be...      1\n",
              "7  One of the Message Boards threads at IMDb had ...      1\n",
              "8  This movie is bad as we all knew it would be. ...      0\n",
              "9  Once upon a time, in Sweden, there was a poor ...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-159996e5-b551-4577-950e-d4e44056d9ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Although Flatliners is 15 years old, tonight w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is a total piece of crap. It is an insult...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>...un-funny and un-entertaining, possibly the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It was high time a movie about the situation i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>My Caddy Limo was destroyed!!! Well, I had one...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Watching this on Comcast On-Demand. Every time...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>This is a cult film for many reasons. First be...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>One of the Message Boards threads at IMDb had ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>This movie is bad as we all knew it would be. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Once upon a time, in Sweden, there was a poor ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-159996e5-b551-4577-950e-d4e44056d9ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-159996e5-b551-4577-950e-d4e44056d9ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-159996e5-b551-4577-950e-d4e44056d9ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "imdb_test.head(n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XaZk5FOPKaVg",
        "outputId": "15ff6072-6f23-4560-93d6-cad476af1262",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What's wrong with this film? Many, many things. The editing tries too hard to look good, and does nothing but confuse the viewer whilst also supplying him/her with a powerful headache. The plot is muddled and obviously prolonged from what started as a short (story or film). The plot only makes for less than ten minutes of good story, and this is just stretched out painfully until it reached the minimum length for a feature film. We all know what happens to things when we stretch them, right? Exactly. They get thinner. In the end, the plot is just so paper-thin that you might even miss it, if you aren't paying attention, which is hard to do when watching this movie. The acting is not even slightly impressive. The characters are poorly written and dull, uninteresting. One of the worst things that are wrong with this film is that apparently, whoever was in charge of the score/soundtrack had no idea what the movie was, or what it was supposed to be about(not that I blame him, I couldn't figure it out either). As a result, half of the music in the film doesn't fit the scenes at all. Also, what was with all the sexual undertones between Eliza Dushku and the main character? Naturally, this was in order to attract young males, but it was just so cheaply done. And did the first scene have anything to do with the rest of the film? On any conceivable level? At all? The two creepy guys didn't seem to have anything to do with the film at all, they were just there in order to have some chase scenes. I doubt anyone would really enjoy a film so poorly put together and such a shameless and awful Hollywood-like attempt at a somewhat interesting idea. But I digress. I recommend this to teenagers with low attention spans who don't mind a really bad horror-thriller as long as there's some sex and gore in it(although that may only be true for the Killer Cut, which I saw). 1/10\n"
          ]
        }
      ],
      "source": [
        "print(imdb_train.loc[0, \"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew6SN9aZKaVg"
      },
      "source": [
        "### loc vs iloc\n",
        "s = pd.Series(list(\"abcdef\"), index=[49, 48, 47, 0, 1, 2])\n",
        "\n",
        "49    a\n",
        "48    b\n",
        "47    c\n",
        "0     d\n",
        "1     e\n",
        "2     f\n",
        "\n",
        "s.loc[0]    # value at index label 0\n",
        "\n",
        "'d'\n",
        "\n",
        "s.iloc[0]   # value at index location 0\n",
        "\n",
        "'a'\n",
        "\n",
        "s.loc[0:1]  # rows at index labels between 0 and 1 (inclusive)\n",
        "\n",
        "0    d\n",
        "1    e\n",
        "\n",
        "s.iloc[0:1] # rows at index location between 0 and 1 (exclusive)\n",
        "\n",
        "49    a\n",
        "\n",
        "Ref: https://stackoverflow.com/questions/31593201/how-are-iloc-and-loc-different#:~:text=The%20main%20distinction%20between%20the,or%20columns)%20at%20integer%20locations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW4NMYT1KaVh"
      },
      "source": [
        "# Matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iQJy1BPKaVh"
      },
      "source": [
        "This is exclusively a visualization library in python. It is employed for visual involving 2D, 3D and animation. It also serves as dependency for other numerous libraries.\n",
        "\n",
        "https://matplotlib.org/1.3.1/index.html\n",
        "\n",
        "https://github.com/rougier/matplotlib-tutorial\n",
        "\n",
        "https://matplotlib.org/3.2.2/gallery/index.html\n",
        "\n",
        "Pyplot module is the most used.\n",
        "\n",
        "<b> Other visualisation libraries built on top of Matplotlib: </b>\n",
        "* seaborn\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvo9IxYMKaVh"
      },
      "source": [
        "# sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlP1FUEfKaVh"
      },
      "source": [
        "Aka Scikit-Learn. An almost-complete library for data analysis and modelling is the <b>sklearn</b> library. It contains various statistical models and few neural network model one might require in any analytic problem. While thre are many modelling libraries out there, <b>sklearn</b> on it's own houses numerous modelling techniques as modules and functions all which come together to make up the library.\n",
        "\n",
        "https://scikit-learn.org/stable/\n",
        "\n",
        "https://scikit-learn.org/stable/getting_started.html\n",
        "\n",
        "### Other libraries for NLP\n",
        "* HuggingFace\n",
        "* Spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaMsOHsqKaVi"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmFh153jKaVi"
      },
      "source": [
        "Unlike data wrangling, this is widely the interesting part in general data analysis. The step here are as follows:\n",
        "\n",
        "$\\bullet$ determine the set of algorithms to try on the data (classification, regression, neural-net etc).\n",
        "\n",
        "$\\bullet$ model design - data splitting.\n",
        "\n",
        "$\\bullet$ model building\n",
        "\n",
        "$\\bullet$ evaluation (metrics)\n",
        "\n",
        "$\\bullet$ model review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "F4vap1XmKaVi"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI1SZ3vCKaVi"
      },
      "source": [
        "<h2><a href=\"https://github.com/lazuxd/simple-imdb-sentiment-analysis/blob/master/sentiment-analysis.ipynb\"> Notebook reference </a></h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKg6ruOiKaVi"
      },
      "source": [
        "# Building a Sentiment Classifier using Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6t0-2ptKaVi"
      },
      "source": [
        "<center><img src=\"https://raw.githubusercontent.com/lazuxd/simple-imdb-sentiment-analysis/master/smiley.jpg\"/></center>\n",
        "<center><i>Image by AbsolutVision @ <a href=\"https://pixabay.com/ro/photos/smiley-emoticon-furie-sup%C4%83rat-2979107/\">pixabay.com</a></i></center>\n",
        "\n",
        "> &nbsp;&nbsp;&nbsp;&nbsp;**Sentiment analysis**, an important area in Natural Language Processing, is the process of automatically detecting affective states of text. Sentiment analysis is widely applied to voice-of-customer materials such as product reviews in online shopping websites like Amazon, movie reviews or social media. It can be just a basic task of classifying the polarity of a text as being positive/negative or it can go beyond polarity, looking at emotional states such as \"happy\", \"angry\", etc.\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;Here we will build a classifier that is able to distinguish movie reviews as being either positive or negative. For that, we will use [Large Movie Review Dataset v1.0](http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz)<sup>(2)</sup> of IMDB movie reviews.\n",
        "This dataset contains 50,000 movie reviews divided evenly into 25k train and 25k test. The labels are balanced between the two classes (positive and negative). <b>Reviews with a score <= 4 out of 10 are labeled negative and those with score >= 7 out of 10 are labeled positive. Neutral reviews are not included in the labeled data.</b> This dataset also contains unlabeled reviews for unsupervised learning; we will not use them here. <b>There are no more than 30 reviews for a particular movie because the ratings of the same movie tend to be correlated. All reviews for a given movie are either in train or test set but not in both, in order to avoid test accuracy gain by memorizing movie-specific terms.</b>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Xc17ZKOnKaVi",
        "outputId": "09cd6f12-cc78-406d-fb14-6deda0622924",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 2)\n",
            "(25000, 2)\n"
          ]
        }
      ],
      "source": [
        "print(imdb_train.shape)\n",
        "print(imdb_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2NWDksZKaVi"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYw8TKr8KaVi"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;After the dataset has been downloaded and extracted from archive we have to transform it into a more suitable form for feeding it into a machine learning model for training. We will start by combining all review data into 2 pandas Data Frames representing the train and test datasets, and then saving them as csv files: *imdb_train.csv* and *imdb_test.csv*.  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;The Data Frames will have the following form:  \n",
        "\n",
        "|text       |label      |\n",
        "|:---------:|:---------:|\n",
        "|review1    |0          |\n",
        "|review2    |1          |\n",
        "|review3    |1          |\n",
        "|.......    |...        |\n",
        "|reviewN    |0          |  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;where:  \n",
        "- review1, review2, ... = the actual text of movie review  \n",
        "- 0 = negative review  \n",
        "- 1 = positive review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvwR6QZ7KaVj"
      },
      "source": [
        "<b>But machine learnng algorithms work only with numerical values.</b> We can't just input the text itself into a machine learning model and have it learn from that. We have to, somehow, <b>represent the text by numbers or vectors of numbers</b>. One way of doing this is by using the **Bag-of-words** model<sup>(3)</sup>, in which a piece of text (often called a **document**) is represented by a <b>vector of the counts of words from a vocabulary in that document. This model doesn't take into account grammar rules or word ordering; all it considers is the frequency of words</b>. If we use the counts of each word independently we name this representation a **unigram**. In general, in a **n-gram** we take into account the counts of <b>each combination of n words from the vocabulary that appears in a given document</b>.  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;For example, consider these two documents:  \n",
        "<br>  \n",
        "<div style=\"font-family: monospace;\"><center><b>d1: \"I am learning\"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b></center></div>  \n",
        "<div style=\"font-family: monospace;\"><center><b>d2: \"Machine learning is cool\"</b></center></div>  \n",
        "<br>\n",
        "The vocabulary of all words encountered in these two sentences is: \n",
        "\n",
        "<br/>  \n",
        "<div style=\"font-family: monospace;\"><center><b>v: [ I, am, learning, machine, is, cool ]</b></center></div>   \n",
        "<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;The unigram representations of d1 and d2:  \n",
        "<br>  \n",
        "\n",
        "|unigram(d1)|I       |am      |learning|machine |is      |cool    |\n",
        "|:---------:|:------:|:------:|:------:|:------:|:------:|:------:|\n",
        "|           |1       |1       |1       |0       |0       |0       |  \n",
        "\n",
        "|unigram(d2)|I       |am      |learning|machine |is      |cool    |\n",
        "|:---------:|:------:|:------:|:------:|:------:|:------:|:------:|\n",
        "|           |0       |0       |1       |1       |1       |1       |\n",
        "  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;And, the bigrams of d1 and d2 are:\n",
        "  \n",
        "|bigram(d1) |I I     |I am    |I learning|...|machine am|machine learning|...|cool is|cool cool|\n",
        "|:---------:|:------:|:------:|:--------:|:-:|:--------:|:--------------:|:-:|:-----:|:-------:|\n",
        "|           |0       |1       |0         |...|0         |0               |...|0      |0        |  \n",
        "\n",
        "|bigram(d2) |I I     |I am    |I learning|...|machine am|machine learning|...|cool is|cool cool|\n",
        "|:---------:|:------:|:------:|:--------:|:-:|:--------:|:--------------:|:-:|:-----:|:-------:|\n",
        "|           |0       |0       |0         |...|0         |1               |...|0      |0        |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMs4QItjKaVj"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;Often, we can achieve slightly better results if instead of counts of words we use something called **term frequency times inverse document frequency** (or **tf-idf**). Maybe it sounds complicated, but it is not. Bear with me, I will explain this. The intuition behind this is the following. So, what's the problem of using just the frequency of terms inside a document? <b>Although some terms may have a high frequency inside documents they may not be so relevant for describing a given document in which they appear. That's because those terms may also have a high frequency across the collection of all documents</b>. For example, a collection of movie reviews may have terms specific to movies/cinematography that are present in almost all documents (they have a high **document frequency**). So, when we encounter those terms in a document this doesn't tell much about whether it is a positive or negative review. We need a way of relating **term frequency** (how frequent a term is inside a document) to **document frequency** (how frequent a term is across the whole collection of documents). That is:  \n",
        "  \n",
        "$$\\begin{align}\\frac{\\text{term frequency}}{\\text{document frequency}} &= \\text{term frequency} \\cdot \\frac{1}{\\text{document frequency}} \\\\ &= \\text{term frequency} \\cdot \\text{inverse document frequency} \\\\ &= \\text{tf} \\cdot \\text{idf}\\end{align}$$  \n",
        "  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;Now, there are more ways used to describe both term frequency and inverse document frequency. But the most common way is by putting them on a logarithmic scale:  \n",
        "  \n",
        "$$tf(t, d) = log(1+f_{t,d})$$  \n",
        "$$idf(t) = log(\\frac{1+N}{1+n_t})$$  \n",
        "  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;where:  \n",
        "$$\\begin{align}f_{t,d} &= \\text{count of term } \\textbf{t} \\text{ in document } \\textbf{d} \\\\  \n",
        "N &= \\text{total number of documents} \\\\  \n",
        "n_t &= \\text{number of documents that contain term } \\textbf{t}\\end{align}$$  \n",
        "  \n",
        "<b>We added 1 in the first logarithm to avoid getting $-\\infty$ when $f_{t,d}$ is 0. In the second logarithm we added one fake document to avoid division by zero.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nneFbP9SKaVj"
      },
      "source": [
        "Before we transform our data into vectors of counts or tf-idf values we should remove English **stopwords**<sup>(6)(7)</sup>. <b>Stopwords are words that are very common in a language</b> and are usually removed in the preprocessing stage of natural text-related tasks like sentiment analysis or search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95b9auslKaVj"
      },
      "source": [
        "<b>Note that we should construct our vocabulary only based on the training set. When we will process the test data in order to make predictions we should use only the vocabulary constructed in the training phase, the rest of the words will be ignored.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu_o2_7aKaVj"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;Now, let's create the data frames and save them as csv files:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VrYZ8U1KaVj"
      },
      "source": [
        "### Text vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOUtfEOLKaVj"
      },
      "source": [
        "Fortunately, for the text vectorization part all the hard work is already done in the Scikit-Learn classes `CountVectorizer`<sup>(8)</sup> and `TfidfTransformer`<sup>(5)</sup>. We will use these classes to transform our csv files into unigram and bigram matrices (using both counts and tf-idf values). (<b>It turns out that if we only use a n-gram for a large n we don't get a good accuracy, we usually use all n-grams up to some n. So, when we say here bigrams we actually refer to uni+bigrams and when we say unigrams it's just unigrams.</b>) Each row in those matrices will represent a document (review) in our dataset, and each column will represent values associated with each word in the vocabulary (in the case of unigrams) or values associated with each combination of maximum 2 words in the vocabulary (bigrams).  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;`CountVectorizer` has a parameter `ngram_range` which expects a tuple of size 2 that controls what n-grams to include. After we constructed a `CountVectorizer` object we should call `.fit()` method with the actual text as a parameter, in order for it to learn the required statistics of our collection of documents. Then, by calling `.transform()` method with our collection of documents it returns the matrix for the n-gram range specified. As the class name suggests, this matrix will contain just the counts. To obtain the tf-idf values, the class `TfidfTransformer` should be used. It has the `.fit()` and `.transform()` methods that are used in a similar way with those of `CountVectorizer`, but they take as input the counts matrix obtained in the previous step and `.transform()` will return a matrix with tf-idf values. We should use `.fit()` only on training data and then store these objects. When we want to evaluate the test score or whenever we want to make a prediction we should use these objects to transform the data before feeding it into our classifier.  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;Note that the matrices generated for our train or test data will be huge, and if we store them as normal numpy arrays they will not even fit into RAM. But most of the entries in these matrices will be zero. So, these Scikit-Learn classes are using Scipy sparse matrices<sup>(9)</sup> (`csr_matrix`<sup>(10)</sup> to be more exactly), which store just the non-zero entries and save a LOT of space.  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;We will use a linear classifier with stochastic gradient descent, `sklearn.linear_model.SGDClassifier`<sup>(11)</sup>, as our model. First we will generate and save our data in 4 forms: unigram and bigram matrix (with both counts and tf-idf values for each). Then we will train and evaluate our model for each these 4 data representations using `SGDClassifier` with the default parameters. After that, we choose the data representation which led to the best score and we will tune the hyper-parameters of our model with this data form using cross-validation in order to obtain the best results.\n",
        "\n",
        "<b>Refs:</b> \n",
        "* Convert a collection of text documents to a matrix of token counts: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "* Convert a collection of raw documents to a matrix of TF-IDF features: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-gmCQ_9dKaVk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKJDdqJ1KaVk"
      },
      "source": [
        "#### Unigram Counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "fkvOuVn8KaVk",
        "outputId": "51536b1d-97dd-4d7f-fdfe-eca4c9f96e05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.73 s, sys: 76.9 ms, total: 4.81 s\n",
            "Wall time: 4.82 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# TRAINING\n",
        "unigram_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
        "unigram_vectorizer.fit(imdb_train['text'].values)\n",
        "dump(unigram_vectorizer, 'data_preprocessors/unigram_vectorizer.joblib')\n",
        "\n",
        "# TESTING\n",
        "unigram_vectorizer = load('data_preprocessors/unigram_vectorizer.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "y4BaMGpUKaVk",
        "outputId": "72a9bcc4-2668-4a04-b365-1d13856591ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'what': 72703,\n",
              " 'wrong': 73842,\n",
              " 'with': 73342,\n",
              " 'this': 66562,\n",
              " 'film': 24536,\n",
              " 'many': 40829,\n",
              " 'things': 66524,\n",
              " 'the': 66339,\n",
              " 'editing': 20934,\n",
              " 'tries': 68148,\n",
              " 'too': 67324,\n",
              " 'hard': 29821,\n",
              " 'to': 67125,\n",
              " 'look': 39364,\n",
              " 'good': 28068,\n",
              " 'and': 3258,\n",
              " 'does': 19421,\n",
              " 'nothing': 46074,\n",
              " 'but': 9881,\n",
              " 'confuse': 14135,\n",
              " 'viewer': 71334,\n",
              " 'whilst': 72787,\n",
              " 'also': 2821,\n",
              " 'supplying': 64539,\n",
              " 'him': 31002,\n",
              " 'her': 30646,\n",
              " 'powerful': 51151,\n",
              " 'headache': 30213,\n",
              " 'plot': 50428,\n",
              " 'is': 34585,\n",
              " 'muddled': 44260,\n",
              " 'obviously': 46550,\n",
              " 'prolonged': 51981,\n",
              " 'from': 26180,\n",
              " 'started': 62903,\n",
              " 'as': 4465,\n",
              " 'short': 59806,\n",
              " 'story': 63422,\n",
              " 'or': 47142,\n",
              " 'only': 46957,\n",
              " 'makes': 40431,\n",
              " 'for': 25450,\n",
              " 'less': 38451,\n",
              " 'than': 66299,\n",
              " 'ten': 66008,\n",
              " 'minutes': 42972,\n",
              " 'of': 46680,\n",
              " 'just': 35787,\n",
              " 'stretched': 63606,\n",
              " 'out': 47449,\n",
              " 'painfully': 48052,\n",
              " 'until': 70237,\n",
              " 'it': 34683,\n",
              " 'reached': 53759,\n",
              " 'minimum': 42913,\n",
              " 'length': 38350,\n",
              " 'feature': 24077,\n",
              " 'we': 72365,\n",
              " 'all': 2662,\n",
              " 'know': 36915,\n",
              " 'happens': 29778,\n",
              " 'when': 72753,\n",
              " 'stretch': 63605,\n",
              " 'them': 66376,\n",
              " 'right': 55827,\n",
              " 'exactly': 22857,\n",
              " 'they': 66474,\n",
              " 'get': 27304,\n",
              " 'thinner': 66537,\n",
              " 'in': 33004,\n",
              " 'end': 21770,\n",
              " 'so': 61380,\n",
              " 'paper': 48292,\n",
              " 'thin': 66516,\n",
              " 'that': 66322,\n",
              " 'you': 74324,\n",
              " 'might': 42658,\n",
              " 'even': 22718,\n",
              " 'miss': 43179,\n",
              " 'if': 32517,\n",
              " 'aren': 4128,\n",
              " 'paying': 48848,\n",
              " 'attention': 4887,\n",
              " 'which': 72773,\n",
              " 'do': 19326,\n",
              " 'watching': 72259,\n",
              " 'movie': 44147,\n",
              " 'acting': 1623,\n",
              " 'not': 46050,\n",
              " 'slightly': 60871,\n",
              " 'impressive': 32949,\n",
              " 'characters': 11635,\n",
              " 'are': 4124,\n",
              " 'poorly': 50821,\n",
              " 'written': 73840,\n",
              " 'dull': 20381,\n",
              " 'uninteresting': 69759,\n",
              " 'one': 46932,\n",
              " 'worst': 73700,\n",
              " 'apparently': 3841,\n",
              " 'whoever': 72910,\n",
              " 'was': 72196,\n",
              " 'charge': 11651,\n",
              " 'score': 58161,\n",
              " 'soundtrack': 61845,\n",
              " 'had': 29369,\n",
              " 'no': 45805,\n",
              " 'idea': 32435,\n",
              " 'supposed': 64551,\n",
              " 'be': 6334,\n",
              " 'about': 1277,\n",
              " 'blame': 7636,\n",
              " 'couldn': 15058,\n",
              " 'figure': 24493,\n",
              " 'either': 21162,\n",
              " 'result': 55342,\n",
              " 'half': 29503,\n",
              " 'music': 44529,\n",
              " 'doesn': 19423,\n",
              " 'fit': 24787,\n",
              " 'scenes': 57878,\n",
              " 'at': 4753,\n",
              " 'sexual': 59123,\n",
              " 'undertones': 69418,\n",
              " 'between': 7110,\n",
              " 'eliza': 21346,\n",
              " 'dushku': 20547,\n",
              " 'main': 40365,\n",
              " 'character': 11615,\n",
              " 'naturally': 45031,\n",
              " 'order': 47196,\n",
              " 'attract': 4909,\n",
              " 'young': 74334,\n",
              " 'males': 40492,\n",
              " 'cheaply': 11791,\n",
              " 'done': 19585,\n",
              " 'did': 18292,\n",
              " 'first': 24750,\n",
              " 'scene': 57873,\n",
              " 'have': 30118,\n",
              " 'anything': 3718,\n",
              " 'rest': 55299,\n",
              " 'on': 46916,\n",
              " 'any': 3703,\n",
              " 'conceivable': 13914,\n",
              " 'level': 38507,\n",
              " 'two': 68769,\n",
              " 'creepy': 15488,\n",
              " 'guys': 29236,\n",
              " 'didn': 18303,\n",
              " 'seem': 58604,\n",
              " 'were': 72601,\n",
              " 'there': 66432,\n",
              " 'some': 61617,\n",
              " 'chase': 11719,\n",
              " 'doubt': 19804,\n",
              " 'anyone': 3715,\n",
              " 'would': 73714,\n",
              " 'really': 53839,\n",
              " 'enjoy': 21922,\n",
              " 'put': 52709,\n",
              " 'together': 67175,\n",
              " 'such': 64115,\n",
              " 'shameless': 59276,\n",
              " 'awful': 5266,\n",
              " 'hollywood': 31355,\n",
              " 'like': 38755,\n",
              " 'attempt': 4873,\n",
              " 'somewhat': 61646,\n",
              " 'interesting': 34079,\n",
              " 'digress': 18404,\n",
              " 'recommend': 54079,\n",
              " 'teenagers': 65844,\n",
              " 'low': 39602,\n",
              " 'spans': 61976,\n",
              " 'who': 72904,\n",
              " 'don': 19563,\n",
              " 'mind': 42844,\n",
              " 'bad': 5502,\n",
              " 'horror': 31685,\n",
              " 'thriller': 66674,\n",
              " 'long': 39320,\n",
              " 'sex': 59098,\n",
              " 'gore': 28160,\n",
              " 'although': 2861,\n",
              " 'may': 41513,\n",
              " 'true': 68360,\n",
              " 'killer': 36566,\n",
              " 'cut': 16122,\n",
              " 'saw': 57693,\n",
              " '10': 39,\n",
              " 'course': 15153,\n",
              " 'very': 71159,\n",
              " 'nice': 45541,\n",
              " 'see': 58585,\n",
              " 'improvements': 32975,\n",
              " 'turkish': 68606,\n",
              " 'industry': 33405,\n",
              " 'however': 31868,\n",
              " 'expected': 23130,\n",
              " 'something': 61638,\n",
              " 'more': 43838,\n",
              " 'creative': 15437,\n",
              " 'togan': 67171,\n",
              " 'gokbakar': 27973,\n",
              " 'starting': 62906,\n",
              " 'script': 58311,\n",
              " 'believe': 6720,\n",
              " 'wise': 73287,\n",
              " 'think': 66526,\n",
              " 'especially': 22482,\n",
              " 'cheesiness': 11865,\n",
              " 'dialogs': 18203,\n",
              " 'putting': 52725,\n",
              " 'audience': 4956,\n",
              " 'position': 50982,\n",
              " 'smart': 61055,\n",
              " 'enough': 21966,\n",
              " 'understand': 69390,\n",
              " 'situations': 60498,\n",
              " 'most': 43995,\n",
              " 'times': 66943,\n",
              " 'unbearable': 69098,\n",
              " 'has': 29999,\n",
              " 'an': 3167,\n",
              " 'obvious': 46549,\n",
              " 'ending': 21795,\n",
              " 'can': 10357,\n",
              " 'easily': 20773,\n",
              " 'guess': 28997,\n",
              " 'murderer': 44460,\n",
              " 'beginning': 6611,\n",
              " 'weakest': 72372,\n",
              " 'part': 48525,\n",
              " 'scenario': 57868,\n",
              " 'impossibility': 32916,\n",
              " 'seriously': 58974,\n",
              " 'mentally': 42221,\n",
              " 'ill': 32591,\n",
              " 'patients': 48716,\n",
              " 'act': 1615,\n",
              " 'normal': 45985,\n",
              " 'people': 49147,\n",
              " 'professionals': 51878,\n",
              " 'away': 5252,\n",
              " 'ever': 22737,\n",
              " 'search': 58447,\n",
              " 'possibility': 51010,\n",
              " 'heavy': 30360,\n",
              " 'medicals': 41923,\n",
              " 'use': 70505,\n",
              " 'medical': 41921,\n",
              " 'terms': 66136,\n",
              " 'cannot': 10442,\n",
              " 'where': 72757,\n",
              " 'staff': 62688,\n",
              " 'searching': 58451,\n",
              " 'dangerous': 16454,\n",
              " 'patient': 48714,\n",
              " 'weapon': 72384,\n",
              " 'protect': 52161,\n",
              " 'themselves': 66387,\n",
              " 'another': 3538,\n",
              " 'weird': 72521,\n",
              " 'point': 50578,\n",
              " 'suitable': 64230,\n",
              " 'dikkat': 18412,\n",
              " 'sahan': 57119,\n",
              " 'cikabilir': 12427,\n",
              " 'title': 67080,\n",
              " 'those': 66615,\n",
              " 'weak': 72366,\n",
              " 'parts': 48584,\n",
              " 'lot': 39486,\n",
              " 'preciosities': 51280,\n",
              " 'depiction': 17633,\n",
              " 'exact': 22853,\n",
              " 'copy': 14776,\n",
              " 'hannibal': 29749,\n",
              " 'appearance': 3852,\n",
              " 'mistake': 43219,\n",
              " 'he': 30211,\n",
              " 'could': 15056,\n",
              " 'his': 31095,\n",
              " 'fuss': 26440,\n",
              " 'greatness': 28550,\n",
              " 'interviews': 34231,\n",
              " 'actor': 1655,\n",
              " 'gave': 26959,\n",
              " 'made': 40170,\n",
              " 'curious': 16037,\n",
              " 'force': 25463,\n",
              " 'gen': 27079,\n",
              " 'total': 67496,\n",
              " 'disappointment': 18642,\n",
              " 'wonder': 73492,\n",
              " 'famous': 23697,\n",
              " 'able': 1231,\n",
              " 'shoot': 59773,\n",
              " 'much': 44241,\n",
              " 'budget': 9496,\n",
              " 'amount': 3107,\n",
              " 'hope': 31595,\n",
              " 'realize': 53831,\n",
              " 'fashionable': 23896,\n",
              " 'play': 50310,\n",
              " 'role': 56269,\n",
              " 'director': 18577,\n",
              " 'said': 57131,\n",
              " 'interview': 34225,\n",
              " 'hitchcock': 31125,\n",
              " 'wisely': 73297,\n",
              " 'night': 45638,\n",
              " 'shyamalan': 60028,\n",
              " 'continued': 14517,\n",
              " 'successfully': 64093,\n",
              " 'should': 59848,\n",
              " 'aware': 5249,\n",
              " 'fact': 23515,\n",
              " 'nor': 45964,\n",
              " 'yet': 74216,\n",
              " 'hoping': 31611,\n",
              " 'careful': 10647,\n",
              " 'next': 45507,\n",
              " 'time': 66925,\n",
              " 'big': 7260,\n",
              " 'les': 38436,\n",
              " 'convoyeurs': 14670,\n",
              " 'attendent': 4884,\n",
              " '2000': 441,\n",
              " 'll': 39101,\n",
              " 'better': 7095,\n",
              " 'year': 74147,\n",
              " 'beautiful': 6440,\n",
              " 'tragicomedy': 67700,\n",
              " 'by': 9962,\n",
              " 'belgian': 6705,\n",
              " 'filmmaker': 24569,\n",
              " 'benoît': 6880,\n",
              " 'mariage': 40941,\n",
              " 'set': 59025,\n",
              " 'industrial': 33396,\n",
              " 'wastelands': 72234,\n",
              " 'wallonia': 72020,\n",
              " 'poelvoorde': 50550,\n",
              " 'plays': 50337,\n",
              " 'father': 23944,\n",
              " 'desperately': 17864,\n",
              " 'wants': 72096,\n",
              " 'son': 61666,\n",
              " 'win': 73157,\n",
              " 'car': 10589,\n",
              " 'lada': 37449,\n",
              " 'break': 8911,\n",
              " 'record': 54116,\n",
              " 'opening': 47033,\n",
              " 'doors': 19676,\n",
              " 'actually': 1670,\n",
              " 'someone': 61624,\n",
              " 'because': 6459,\n",
              " 'himself': 31014,\n",
              " 'never': 45429,\n",
              " 'further': 26422,\n",
              " 'reporter': 55024,\n",
              " 'local': 39160,\n",
              " 'news': 45475,\n",
              " 'newspaper': 45487,\n",
              " 'ironically': 34512,\n",
              " 'called': 10210,\n",
              " 'espoir': 22498,\n",
              " 'works': 73646,\n",
              " 'planned': 50247,\n",
              " 'best': 7045,\n",
              " 'compared': 13695,\n",
              " 'aki': 2426,\n",
              " 'kaurismäki': 36177,\n",
              " 'drifting': 20120,\n",
              " 'clouds': 12959,\n",
              " 'dramatic': 19974,\n",
              " 'humour': 32091,\n",
              " 'darker': 16548,\n",
              " 'tone': 67292,\n",
              " 'melancholic': 42049,\n",
              " 'depressing': 17678,\n",
              " 'upbeat': 70335,\n",
              " 'without': 73364,\n",
              " 'being': 6663,\n",
              " 'unrealistically': 70029,\n",
              " 'happy': 29790,\n",
              " 'absurd': 1343,\n",
              " 'making': 40441,\n",
              " 'unbelievable': 69113,\n",
              " 'finds': 24635,\n",
              " 'stunning': 63811,\n",
              " 'images': 32657,\n",
              " 'bleak': 7713,\n",
              " 'settings': 59041,\n",
              " 'artificial': 4416,\n",
              " 'thing': 66518,\n",
              " 'shot': 59838,\n",
              " 'fame': 23676,\n",
              " 'brilliant': 9114,\n",
              " 'cult': 15962,\n",
              " 'classic': 12676,\n",
              " 'est': 22529,\n",
              " 'arrivé': 4335,\n",
              " 'près': 52289,\n",
              " 'de': 16742,\n",
              " 'chez': 11979,\n",
              " 'vous': 71773,\n",
              " 'played': 50315,\n",
              " 'charismatic': 11663,\n",
              " 'hitman': 31153,\n",
              " 'ben': 6804,\n",
              " 'since': 60351,\n",
              " 'then': 66390,\n",
              " 'small': 61038,\n",
              " 'roles': 56270,\n",
              " 'films': 24581,\n",
              " 'released': 54664,\n",
              " 'netherlands': 45377,\n",
              " 'convinced': 14659,\n",
              " 'own': 47889,\n",
              " 'capabilities': 10484,\n",
              " 'offered': 46704,\n",
              " 'reprises': 55065,\n",
              " 'return': 55455,\n",
              " 'leading': 38087,\n",
              " 'lca': 38067,\n",
              " 'anymore': 3713,\n",
              " 'simply': 60326,\n",
              " 'man': 40591,\n",
              " 'stupid': 63831,\n",
              " 'evil': 22793,\n",
              " 'family': 23690,\n",
              " 'misery': 43083,\n",
              " 'torn': 67427,\n",
              " 'remorse': 54817,\n",
              " 'must': 44560,\n",
              " 'heard': 30282,\n",
              " 'read': 53777,\n",
              " 'praising': 51216,\n",
              " 'midnight': 42627,\n",
              " 'meat': 41855,\n",
              " 'train': 67711,\n",
              " 'based': 6117,\n",
              " 'clive': 12897,\n",
              " 'barker': 5997,\n",
              " 'supposedly': 64552,\n",
              " 'adaptation': 1704,\n",
              " 'work': 73616,\n",
              " 'original': 47274,\n",
              " 'hellraiser': 30530,\n",
              " 'directed': 18564,\n",
              " 'far': 23785,\n",
              " 'express': 23267,\n",
              " 'mixed': 43280,\n",
              " 'sentiments': 58866,\n",
              " 'my': 44639,\n",
              " 'viewing': 71337,\n",
              " 'experience': 23157,\n",
              " 'appropriate': 3957,\n",
              " 'term': 66118,\n",
              " 'summarize': 64297,\n",
              " 'whole': 72911,\n",
              " 'word': 73599,\n",
              " 'nauseating': 45060,\n",
              " 'violence': 71466,\n",
              " 'sadistic': 57071,\n",
              " 'extreme': 23374,\n",
              " 'undoubtedly': 69471,\n",
              " 'attracts': 4917,\n",
              " 'fanatic': 23703,\n",
              " 'enthusiasts': 22073,\n",
              " 'indescribably': 33291,\n",
              " 'gratuitous': 28491,\n",
              " 'exploitative': 23212,\n",
              " 'normally': 45989,\n",
              " 'speaking': 62041,\n",
              " 'pro': 51766,\n",
              " 'least': 38132,\n",
              " 'serve': 58999,\n",
              " 'kind': 36608,\n",
              " 'purpose': 52656,\n",
              " 'butchering': 9886,\n",
              " 'literally': 39015,\n",
              " 'depicted': 17631,\n",
              " 'exclusively': 22965,\n",
              " 'meant': 41842,\n",
              " 'shock': 59724,\n",
              " 'repulse': 55096,\n",
              " 'viewers': 71335,\n",
              " 'nerve': 45353,\n",
              " 'systems': 65167,\n",
              " 'upset': 70400,\n",
              " 'stomachs': 63345,\n",
              " 'isn': 34644,\n",
              " 'fully': 26316,\n",
              " 'effective': 21017,\n",
              " 'due': 20337,\n",
              " 'digital': 18388,\n",
              " 'computer': 13876,\n",
              " 'effects': 21020,\n",
              " 'shortcomings': 59815,\n",
              " 'bigger': 7271,\n",
              " 'pointless': 50587,\n",
              " 'perhaps': 49254,\n",
              " 'focus': 25291,\n",
              " 'elements': 21277,\n",
              " 'basic': 6143,\n",
              " 'concept': 13927,\n",
              " 'definitely': 17179,\n",
              " 'promising': 51999,\n",
              " 'multiple': 44365,\n",
              " 'sequences': 58909,\n",
              " 'freezer': 26000,\n",
              " 'room': 56383,\n",
              " 'example': 22881,\n",
              " 'oozing': 47023,\n",
              " 'nail': 44803,\n",
              " 'biting': 7497,\n",
              " 'suspense': 64720,\n",
              " 'macabre': 40010,\n",
              " 'atmosphere': 4818,\n",
              " 'unfortunately': 69622,\n",
              " 'pacing': 47964,\n",
              " 'uneven': 69536,\n",
              " 'elaboration': 21196,\n",
              " 'potentially': 51079,\n",
              " 'fantastic': 23766,\n",
              " 'unnecessarily': 69913,\n",
              " 'convoluted': 14667,\n",
              " 'presumably': 51554,\n",
              " 'processing': 51810,\n",
              " 'into': 34255,\n",
              " 'responsible': 55291,\n",
              " 'irregularities': 34532,\n",
              " 'honestly': 31487,\n",
              " 'feel': 24123,\n",
              " 'denouement': 17560,\n",
              " 'well': 72557,\n",
              " 'vinnie': 71450,\n",
              " 'jones': 35510,\n",
              " 'introduces': 34294,\n",
              " 'leon': 38389,\n",
              " 'aspiring': 4569,\n",
              " 'photographer': 49749,\n",
              " 'new': 45440,\n",
              " 'york': 74303,\n",
              " 'whose': 72955,\n",
              " 'agent': 2164,\n",
              " 'advises': 1972,\n",
              " 'truly': 68377,\n",
              " 'menacing': 42159,\n",
              " 'face': 23484,\n",
              " 'city': 12569,\n",
              " 'through': 66699,\n",
              " 'sinister': 60397,\n",
              " 'pictures': 49867,\n",
              " 'becomes': 6485,\n",
              " 'obsessed': 46510,\n",
              " 'stalking': 62763,\n",
              " 'introvert': 34304,\n",
              " 'suspiciously': 64730,\n",
              " 'behaving': 6632,\n",
              " 'butcher': 9883,\n",
              " 'always': 2893,\n",
              " 'awaits': 5233,\n",
              " 'turns': 68628,\n",
              " 'relentless': 54673,\n",
              " 'serial': 58965,\n",
              " 'crushes': 15827,\n",
              " 'victims': 71263,\n",
              " 'hammer': 29610,\n",
              " 'motivations': 44039,\n",
              " 'behavior': 6633,\n",
              " 'suggest': 64205,\n",
              " 'substantial': 64019,\n",
              " 'going': 27963,\n",
              " 'rails': 53273,\n",
              " 'takes': 65348,\n",
              " 'place': 50189,\n",
              " 'unsettling': 70134,\n",
              " 'locations': 39178,\n",
              " 'subway': 64078,\n",
              " 'stations': 62949,\n",
              " 'animal': 3408,\n",
              " 'abattoirs': 1160,\n",
              " 'plus': 50496,\n",
              " 'benefices': 6836,\n",
              " 'performances': 49242,\n",
              " 'truckload': 68346,\n",
              " 'downright': 19885,\n",
              " 'disturbing': 19200,\n",
              " 'cadavers': 10065,\n",
              " 'hooks': 31557,\n",
              " 'carriages': 10802,\n",
              " 'smeared': 61076,\n",
              " 'blood': 7852,\n",
              " 'ryûhei': 56936,\n",
              " 'kitamura': 36734,\n",
              " 'versus': 71144,\n",
              " 'godzilla': 27932,\n",
              " 'final': 24608,\n",
              " 'wars': 72184,\n",
              " 'take': 65333,\n",
              " 'full': 26307,\n",
              " 'advantage': 1929,\n",
              " 'leaves': 38150,\n",
              " 'questions': 52961,\n",
              " 'unanswered': 69057,\n",
              " 'still': 63226,\n",
              " 'deserved': 17807,\n",
              " 'clarifying': 12653,\n",
              " 'finale': 24609,\n",
              " 'intriguing': 34286,\n",
              " 'haunting': 30103,\n",
              " 'defaults': 17096,\n",
              " 'intended': 34005,\n",
              " 'offended': 46692,\n",
              " 'maybe': 41519,\n",
              " 'looking': 39372,\n",
              " 'coherence': 13224,\n",
              " 'clarity': 12658,\n",
              " 'leave': 38145,\n",
              " 'alone': 2779,\n",
              " 'sad': 57047,\n",
              " 'dvd': 20584,\n",
              " 'probably': 51773,\n",
              " 'delirious': 17348,\n",
              " 'how': 31858,\n",
              " 'often': 46741,\n",
              " 'laugh': 37918,\n",
              " 'stand': 62796,\n",
              " 'up': 70331,\n",
              " 'comedy': 13498,\n",
              " 'routines': 56595,\n",
              " 'richard': 55716,\n",
              " 'pryor': 52287,\n",
              " 'during': 20531,\n",
              " 'greatest': 28547,\n",
              " 'old': 46830,\n",
              " 'eddie': 20900,\n",
              " 'murphy': 44485,\n",
              " 'raw': 53693,\n",
              " 'funny': 26385,\n",
              " 'knew': 36865,\n",
              " 'got': 28216,\n",
              " 'inspiration': 33864,\n",
              " 'now': 46152,\n",
              " 'older': 46834,\n",
              " 'seen': 58613,\n",
              " 'both': 8583,\n",
              " 'comedians': 13489,\n",
              " 'after': 2121,\n",
              " 'everybody': 22763,\n",
              " 'steals': 63007,\n",
              " 'while': 72784,\n",
              " 'lovingly': 39599,\n",
              " 'borrowed': 8538,\n",
              " 'huge': 31974,\n",
              " 'difference': 18334,\n",
              " 'provocative': 52241,\n",
              " 'thoughtful': 66622,\n",
              " 'before': 6579,\n",
              " 'needed': 45204,\n",
              " 'these': 66458,\n",
              " 'days': 16710,\n",
              " 'boring': 8512,\n",
              " 'once': 46921,\n",
              " 'upon': 70377,\n",
              " 'king': 36639,\n",
              " 'castle': 10974,\n",
              " 'built': 9563,\n",
              " 'funniest': 26380,\n",
              " 'white': 72852,\n",
              " 'housewife': 31842,\n",
              " 'appreciate': 3933,\n",
              " 'laurence': 37964,\n",
              " 'fishburne': 24762,\n",
              " 'our': 47440,\n",
              " 'finest': 24648,\n",
              " 'actors': 1657,\n",
              " 'appreciates': 3935,\n",
              " 'deep': 17059,\n",
              " 'cover': 15193,\n",
              " 'incredible': 33223,\n",
              " 'range': 53455,\n",
              " 'directorial': 18579,\n",
              " 'debut': 16868,\n",
              " 'prove': 52211,\n",
              " 'quite': 53042,\n",
              " 'lower': 39612,\n",
              " 'manhattan': 40685,\n",
              " 'junky': 35761,\n",
              " 'worlds': 73658,\n",
              " 'reality': 53826,\n",
              " 'crime': 15540,\n",
              " 'life': 38683,\n",
              " 'glorified': 27794,\n",
              " 'action': 1628,\n",
              " 'em': 21444,\n",
              " 'ups': 70398,\n",
              " 'mr': 44205,\n",
              " 'usual': 70535,\n",
              " 'contribution': 14579,\n",
              " 'incredibly': 33225,\n",
              " 'subtle': 64049,\n",
              " 'relationships': 54642,\n",
              " 'love': 39562,\n",
              " 'larry': 37791,\n",
              " 'anthony': 3590,\n",
              " 'hopkins': 31612,\n",
              " 'go': 27863,\n",
              " 'each': 20694,\n",
              " 'other': 47407,\n",
              " 'day': 16697,\n",
              " 'am': 2906,\n",
              " 'glad': 27638,\n",
              " 'say': 57715,\n",
              " 'almost': 2768,\n",
              " 'positive': 50986,\n",
              " 'karas': 36029,\n",
              " 'tasuiev': 65648,\n",
              " 'sisters': 60472,\n",
              " 'renaissance': 54838,\n",
              " 'firstly': 24752,\n",
              " 'looks': 39377,\n",
              " 'ought': 47433,\n",
              " 'boys': 8714,\n",
              " 'adventure': 1936,\n",
              " 'tale': 65365,\n",
              " 'cop': 14738,\n",
              " 'investigation': 34378,\n",
              " 'missing': 43192,\n",
              " 'scientist': 58114,\n",
              " 'ilona': 32642,\n",
              " 'geneticist': 27128,\n",
              " 'researcher': 55145,\n",
              " 'avalon': 5144,\n",
              " 'company': 13686,\n",
              " 'bislane': 7470,\n",
              " 'though': 66619,\n",
              " 'known': 36924,\n",
              " 'sin': 60346,\n",
              " 'appreciated': 3934,\n",
              " 'connoisseurs': 14230,\n",
              " 'french': 26017,\n",
              " 'comics': 13523,\n",
              " 'aficionados': 2086,\n",
              " 'will': 73091,\n",
              " 'meaningful': 41829,\n",
              " 'enriched': 21982,\n",
              " 'collection': 13330,\n",
              " 'last': 37840,\n",
              " 'week': 72452,\n",
              " 'date': 16632,\n",
              " 'their': 66367,\n",
              " 'lines': 38885,\n",
              " 'endearing': 21777,\n",
              " 'parisian': 48450,\n",
              " 'top': 67361,\n",
              " 'displayed': 19007,\n",
              " 'find': 24629,\n",
              " 'woman': 73473,\n",
              " 'rising': 55956,\n",
              " 'star': 62848,\n",
              " 'genetic': 27126,\n",
              " 'research': 55143,\n",
              " 'mildly': 42725,\n",
              " 'hot': 31769,\n",
              " 'blonde': 7845,\n",
              " 'rebel': 53923,\n",
              " 'sister': 60469,\n",
              " 'erotically': 22371,\n",
              " 'preferable': 51377,\n",
              " 'me': 41798,\n",
              " 'oldie': 46837,\n",
              " 'aficionado': 2085,\n",
              " 'tv': 68685,\n",
              " 'series': 58970,\n",
              " 'marvelously': 41169,\n",
              " 'cartoon': 10850,\n",
              " 'replay': 54990,\n",
              " 'wild': 73052,\n",
              " 'west': 72626,\n",
              " 'episode': 22218,\n",
              " 'here': 30670,\n",
              " 'mythological': 44698,\n",
              " 'past': 48644,\n",
              " 'replaced': 54985,\n",
              " 'equally': 22259,\n",
              " 'future': 26452,\n",
              " 'jaded': 34853,\n",
              " 'blasé': 7688,\n",
              " 'sense': 58812,\n",
              " 'thrilling': 66676,\n",
              " 'suspenseful': 64721,\n",
              " 'paced': 47944,\n",
              " 'seducing': 58578,\n",
              " 'hypnotic': 32308,\n",
              " 'moreover': 43850,\n",
              " 'achieves': 1537,\n",
              " 'sketching': 60582,\n",
              " 'albeit': 2496,\n",
              " 'briefly': 9072,\n",
              " 'world': 73651,\n",
              " 'nakata': 44833,\n",
              " 'jonas': 35503,\n",
              " 'mueller': 44267,\n",
              " 'goran': 28147,\n",
              " 'farfella': 23809,\n",
              " 'telling': 65950,\n",
              " 'distant': 19136,\n",
              " 'childhood': 12045,\n",
              " 'kasbah': 36090,\n",
              " 'liked': 38759,\n",
              " 'certain': 11378,\n",
              " 'gentleness': 27178,\n",
              " 'affability': 2019,\n",
              " 'adventurousness': 1945,\n",
              " 'professional': 51875,\n",
              " 'assured': 4681,\n",
              " 'among': 3093,\n",
              " 'cartoons': 10859,\n",
              " 'linklater': 38910,\n",
              " 'dick': 18255,\n",
              " 'stood': 63368,\n",
              " 'beauty': 6446,\n",
              " 'genuine': 27187,\n",
              " 'excitement': 22946,\n",
              " 'thought': 66621,\n",
              " 'futuristic': 26459,\n",
              " 'devices': 18074,\n",
              " 'conventional': 14617,\n",
              " 'vividly': 71618,\n",
              " 'eerie': 20997,\n",
              " 'invisibility': 34408,\n",
              " 'costumes': 15025,\n",
              " 'advisable': 1965,\n",
              " 'exotic': 23102,\n",
              " 'names': 44855,\n",
              " 'mostly': 44002,\n",
              " 'gathered': 26919,\n",
              " 'arts': 4439,\n",
              " 'entertainment': 22058,\n",
              " 'naghib': 44790,\n",
              " 'none': 45903,\n",
              " 'seems': 58611,\n",
              " 'noticed': 46081,\n",
              " 'poster': 51021,\n",
              " 'features': 24080,\n",
              " 'rourke': 56576,\n",
              " 'alike': 2642,\n",
              " 'guy': 29233,\n",
              " 'marv': 41160,\n",
              " 'make': 40421,\n",
              " 'rip': 55918,\n",
              " 'off': 46684,\n",
              " 'paragon': 48346,\n",
              " 'originality': 47275,\n",
              " 'resemblance': 55150,\n",
              " 'miller': 42783,\n",
              " 'namely': 44853,\n",
              " 'decayed': 16900,\n",
              " 'society': 61434,\n",
              " 'brio': 9137,\n",
              " 'hero': 30717,\n",
              " 'cross': 15705,\n",
              " 'willis': 73120,\n",
              " 'persona': 49385,\n",
              " 'previous': 51620,\n",
              " 'hand': 29650,\n",
              " 'breathes': 8946,\n",
              " 'public': 52406,\n",
              " 'air': 2339,\n",
              " 'brim': 9118,\n",
              " 'straight': 63467,\n",
              " 'kids': 36529,\n",
              " 'naughtier': 45049,\n",
              " 'mean': 41813,\n",
              " 'cause': 11141,\n",
              " 'bit': 7485,\n",
              " 'nudity': 46209,\n",
              " 'display': 19006,\n",
              " 'retort': 55421,\n",
              " 'traits': 67734,\n",
              " 'mentioned': 42224,\n",
              " 'characteristic': 11625,\n",
              " 'clichés': 12822,\n",
              " 'common': 13635,\n",
              " 'places': 50196,\n",
              " 'adult': 1908,\n",
              " 'brought': 9307,\n",
              " 'screen': 58264,\n",
              " 'bears': 6389,\n",
              " 'resemblances': 55151,\n",
              " 'fair': 23573,\n",
              " 'every': 22760,\n",
              " 'ring': 55881,\n",
              " 'its': 34721,\n",
              " 'eragorn': 22296,\n",
              " 'admit': 1833,\n",
              " 'partial': 48540,\n",
              " 'tales': 65373,\n",
              " 'rather': 53602,\n",
              " 'undemanding': 69283,\n",
              " 'specialty': 62073,\n",
              " 'watch': 72246,\n",
              " 'loved': 39570,\n",
              " 'classics': 12682,\n",
              " 'tom': 67237,\n",
              " 'wopat': 73597,\n",
              " 'john': 35445,\n",
              " 'schneider': 58005,\n",
              " 'catherine': 11084,\n",
              " 'bach': 5421,\n",
              " 'sorrell': 61776,\n",
              " 'booke': 8380,\n",
              " 'james': 34916,\n",
              " 'denver': 17589,\n",
              " 'pyle': 52763,\n",
              " 'sonny': 61696,\n",
              " 'shroyer': 59957,\n",
              " 'dissappoint': 19077,\n",
              " 'badly': 5535,\n",
              " 'starts': 62913,\n",
              " 'bo': 8022,\n",
              " 'luke': 39753,\n",
              " 'running': 56810,\n",
              " 'moonshine': 43755,\n",
              " 'jesse': 35237,\n",
              " 'real': 53809,\n",
              " 'portrays': 50954,\n",
              " 'unimaginable': 69724,\n",
              " 'doing': 19472,\n",
              " 'happened': 29774,\n",
              " 'uncle': 69181,\n",
              " 'honest': 31486,\n",
              " 'law': 37996,\n",
              " 'abiding': 1219,\n",
              " 'criminal': 15549,\n",
              " 'smoking': 61133,\n",
              " 'weed': 72446,\n",
              " 'governor': 28270,\n",
              " 'georgia': 27228,\n",
              " 'extension': 23303,\n",
              " 'adding': 1729,\n",
              " 'dukes': 20375,\n",
              " 'hazzard': 30199,\n",
              " 'reunion': 55463,\n",
              " 'question': 52954,\n",
              " 'died': 18307,\n",
              " 'boss': 8563,\n",
              " 'hogg': 31267,\n",
              " 'alive': 2656,\n",
              " '1997': 413,\n",
              " 'rosco': 56440,\n",
              " 'ran': 53427,\n",
              " 'magical': 40251,\n",
              " 'came': 10270,\n",
              " 'back': 5436,\n",
              " 'been': 6543,\n",
              " 'dead': 16746,\n",
              " '11': 85,\n",
              " 'years': 74158,\n",
              " 'wanted': 72091,\n",
              " 'friendly': 26103,\n",
              " 'living': 39079,\n",
              " 'show': 59873,\n",
              " 'disgusting': 18840,\n",
              " 'disgraced': 18827,\n",
              " 'want': 72088,\n",
              " 'movies': 44164,\n",
              " 'buy': 9929,\n",
              " 'walmart': 72031,\n",
              " 'com': 13449,\n",
              " 'includes': 33137,\n",
              " 'cast': 10955,\n",
              " 'waste': 72229,\n",
              " 'your': 74349,\n",
              " 'worth': 73702,\n",
              " 'cd': 11214,\n",
              " 'lisa': 38972,\n",
              " 'baumer': 6280,\n",
              " 'ida': 32432,\n",
              " 'galli': 26645,\n",
              " 'adulteress': 1912,\n",
              " 'wife': 73028,\n",
              " 'businessman': 9850,\n",
              " 'inherits': 33650,\n",
              " '1million': 429,\n",
              " 'insurance': 33959,\n",
              " 'husband': 32194,\n",
              " 'killed': 36565,\n",
              " 'plane': 50233,\n",
              " 'crash': 15364,\n",
              " 'business': 9847,\n",
              " 'trip': 68195,\n",
              " 'initially': 33669,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "unigram_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "rmLtnFWaKaVk"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(unigram_vectorizer.vocabulary_.items(), columns=['Vocabulary', 'Frequency'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "WssxLk9pKaVl",
        "outputId": "df6ad571-2484-454c-d532-3a7e4c007167",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 74849 entries, 0 to 74848\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Vocabulary  74849 non-null  object\n",
            " 1   Frequency   74849 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "3oVmpc14KaVl"
      },
      "outputs": [],
      "source": [
        "df.sort_values(by=\"Frequency\", axis=0, ascending=False, inplace=True, kind='quicksort', na_position='last')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "fpkHzxTMKaVl",
        "outputId": "ec60e17e-5cfc-4421-a709-49de6e8978f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Vocabulary  Frequency\n",
              "68294  üvegtigris      74848\n",
              "27210        über      74847\n",
              "65842      østbye      74846\n",
              "58654        ísnt      74845\n",
              "36430          ís      74844\n",
              "56874      êxtase      74843\n",
              "17275       évery      74842\n",
              "48490         étc      74841\n",
              "37066        état      74840\n",
              "68463       était      74839\n",
              "39069     émigrés      74838\n",
              "36928      émigré      74837\n",
              "51426        élan      74836\n",
              "65957       écran      74835\n",
              "18546    æsthetic      74834\n",
              "69980        åmål      74833\n",
              "65829         åge      74832\n",
              "56611   äänekoski      74831\n",
              "37520      ääliöt      74830\n",
              "55592          är      74829"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8beb6c30-e0ec-4ace-9362-20cc4512abfc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Vocabulary</th>\n",
              "      <th>Frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>68294</th>\n",
              "      <td>üvegtigris</td>\n",
              "      <td>74848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27210</th>\n",
              "      <td>über</td>\n",
              "      <td>74847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65842</th>\n",
              "      <td>østbye</td>\n",
              "      <td>74846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58654</th>\n",
              "      <td>ísnt</td>\n",
              "      <td>74845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36430</th>\n",
              "      <td>ís</td>\n",
              "      <td>74844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56874</th>\n",
              "      <td>êxtase</td>\n",
              "      <td>74843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17275</th>\n",
              "      <td>évery</td>\n",
              "      <td>74842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48490</th>\n",
              "      <td>étc</td>\n",
              "      <td>74841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37066</th>\n",
              "      <td>état</td>\n",
              "      <td>74840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68463</th>\n",
              "      <td>était</td>\n",
              "      <td>74839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39069</th>\n",
              "      <td>émigrés</td>\n",
              "      <td>74838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36928</th>\n",
              "      <td>émigré</td>\n",
              "      <td>74837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51426</th>\n",
              "      <td>élan</td>\n",
              "      <td>74836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65957</th>\n",
              "      <td>écran</td>\n",
              "      <td>74835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18546</th>\n",
              "      <td>æsthetic</td>\n",
              "      <td>74834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69980</th>\n",
              "      <td>åmål</td>\n",
              "      <td>74833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65829</th>\n",
              "      <td>åge</td>\n",
              "      <td>74832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56611</th>\n",
              "      <td>äänekoski</td>\n",
              "      <td>74831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37520</th>\n",
              "      <td>ääliöt</td>\n",
              "      <td>74830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55592</th>\n",
              "      <td>är</td>\n",
              "      <td>74829</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8beb6c30-e0ec-4ace-9362-20cc4512abfc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8beb6c30-e0ec-4ace-9362-20cc4512abfc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8beb6c30-e0ec-4ace-9362-20cc4512abfc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "df.head(n=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "rJd6nBnGKaVl",
        "outputId": "78b628df-0da3-4ebe-c1d8-bc2491b9ed51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Vocabulary  Frequency\n",
              "28841             02         19\n",
              "62974           01pm         18\n",
              "23930             01         17\n",
              "10618            00s         16\n",
              "64118           00pm         15\n",
              "32178           00am         14\n",
              "27368        0093638         13\n",
              "61314           0083         12\n",
              "61313           0080         11\n",
              "61762           0079         10\n",
              "8849             007          9\n",
              "16439            006          8\n",
              "46499         003830          7\n",
              "53765            001          6\n",
              "73869           000s          5\n",
              "24124          00015          4\n",
              "16976          00001          3\n",
              "61616  0000000000001          2\n",
              "7984             000          1\n",
              "4545              00          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2fc52fc-731e-4626-85f5-284ef6e139b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Vocabulary</th>\n",
              "      <th>Frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28841</th>\n",
              "      <td>02</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62974</th>\n",
              "      <td>01pm</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23930</th>\n",
              "      <td>01</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10618</th>\n",
              "      <td>00s</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64118</th>\n",
              "      <td>00pm</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32178</th>\n",
              "      <td>00am</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27368</th>\n",
              "      <td>0093638</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61314</th>\n",
              "      <td>0083</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61313</th>\n",
              "      <td>0080</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61762</th>\n",
              "      <td>0079</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8849</th>\n",
              "      <td>007</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>006</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46499</th>\n",
              "      <td>003830</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53765</th>\n",
              "      <td>001</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73869</th>\n",
              "      <td>000s</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24124</th>\n",
              "      <td>00015</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16976</th>\n",
              "      <td>00001</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61616</th>\n",
              "      <td>0000000000001</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7984</th>\n",
              "      <td>000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4545</th>\n",
              "      <td>00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2fc52fc-731e-4626-85f5-284ef6e139b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c2fc52fc-731e-4626-85f5-284ef6e139b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c2fc52fc-731e-4626-85f5-284ef6e139b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "df.tail(n=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "WU_57FZAKaVl",
        "outputId": "a53816b2-9ca4-495a-bcef-29b8c994053e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7.02 s, sys: 23.4 ms, total: 7.04 s\n",
            "Wall time: 8.35 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# TRAINING\n",
        "X_train_unigram = unigram_vectorizer.transform(imdb_train['text'].values)\n",
        "save_npz('vectorized_data/X_train_unigram.npz', X_train_unigram)\n",
        "\n",
        "# TESTING\n",
        "X_train_unigram = load_npz('vectorized_data/X_train_unigram.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yph7cg5LKaVm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA1s2nxVKaVm"
      },
      "source": [
        "<b> fit_transform </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZEj_ZCcKaVm"
      },
      "source": [
        "#### Unigram Tf-Idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "5f6hgrvmKaVm",
        "outputId": "5474b2f4-af84-4df3-d37d-1051bb6b46af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 22.9 ms, sys: 4.9 ms, total: 27.8 ms\n",
            "Wall time: 31.4 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# TRAINING\n",
        "unigram_tf_idf_transformer = TfidfTransformer()\n",
        "unigram_tf_idf_transformer.fit(X_train_unigram)\n",
        "dump(unigram_tf_idf_transformer, 'data_preprocessors/unigram_tf_idf_transformer.joblib')\n",
        "\n",
        "# TESTING\n",
        "unigram_tf_idf_transformer = load('data_preprocessors/unigram_tf_idf_transformer.joblib') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "B0TcsjGOKaVm",
        "outputId": "1e717eac-7da3-4dc1-a410-8399a0713aac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.43 s, sys: 57.8 ms, total: 3.48 s\n",
            "Wall time: 3.48 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# TRAINING\n",
        "X_train_unigram_tf_idf = unigram_tf_idf_transformer.transform(X_train_unigram)\n",
        "save_npz('vectorized_data/X_train_unigram_tf_idf.npz', X_train_unigram_tf_idf)\n",
        "\n",
        "# TESTING\n",
        "X_train_unigram_tf_idf = load_npz('vectorized_data/X_train_unigram_tf_idf.npz')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6o1t5whKaVn"
      },
      "source": [
        "#### Bigram Counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "jW7gqtHBKaVn",
        "outputId": "ae41694b-e7c8-4cd0-b34b-f1a30422e7cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 33.8 s, sys: 872 ms, total: 34.7 s\n",
            "Wall time: 34.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# TRAINING\n",
        "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
        "bigram_vectorizer.fit(imdb_train['text'].values)\n",
        "dump(bigram_vectorizer, 'data_preprocessors/bigram_vectorizer.joblib')\n",
        "\n",
        "# TESTING\n",
        "bigram_vectorizer = load('data_preprocessors/bigram_vectorizer.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "eznlgiTNKaVn",
        "outputId": "487166ab-a151-48c7-e4c7-56241bb7edcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 12.7 s, sys: 71.8 ms, total: 12.8 s\n",
            "Wall time: 13 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# TRAINING\n",
        "X_train_bigram = bigram_vectorizer.transform(imdb_train['text'].values)\n",
        "save_npz('vectorized_data/X_train_bigram.npz', X_train_bigram)\n",
        "\n",
        "# TESTING\n",
        "X_train_bigram = load_npz('vectorized_data/X_train_bigram.npz')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD72lr6pKaVn"
      },
      "source": [
        "#### Bigram Tf-Idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "PN_l3vtsKaVn",
        "outputId": "42341991-497f-4995-9f39-13226eb8c502",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 165 ms, sys: 31 ms, total: 196 ms\n",
            "Wall time: 197 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# TRAINING\n",
        "bigram_tf_idf_transformer = TfidfTransformer()\n",
        "bigram_tf_idf_transformer.fit(X_train_bigram)\n",
        "dump(bigram_tf_idf_transformer, 'data_preprocessors/bigram_tf_idf_transformer.joblib')\n",
        "\n",
        "# TESTING\n",
        "bigram_tf_idf_transformer = load('data_preprocessors/bigram_tf_idf_transformer.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "j-G56aaPKaVn"
      },
      "outputs": [],
      "source": [
        "X_train_bigram_tf_idf = bigram_tf_idf_transformer.transform(X_train_bigram)\n",
        "save_npz('vectorized_data/X_train_bigram_tf_idf.npz', X_train_bigram_tf_idf)\n",
        "\n",
        "# X_train_bigram_tf_idf = load_npz('vectorized_data/X_train_bigram_tf_idf.npz')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbG4T3H7KaVn"
      },
      "source": [
        "### Choosing data format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfwTRqGpKaVo"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;Now, for each data form we split it into train & validation sets, train a `SGDClassifier` and output the score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "20qYoKfVKaVo"
      },
      "outputs": [],
      "source": [
        "def train_and_show_scores(X: csr_matrix, y: np.array, title: str) -> None:\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "        X, y, train_size=0.75, stratify=y\n",
        "    )\n",
        "\n",
        "    clf = SGDClassifier()\n",
        "    clf.fit(X_train, y_train)\n",
        "    train_score = clf.score(X_train, y_train)\n",
        "    valid_score = clf.score(X_valid, y_valid)\n",
        "    print(f'{title}\\nTrain score: {round(train_score, 2)} ; Validation score: {round(valid_score, 2)}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "WgqNlzYxKaVo"
      },
      "outputs": [],
      "source": [
        "y_train = imdb_train['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "kZNe74vjKaVo"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "AXyuXondKaVo",
        "outputId": "7990efd0-ab7d-448f-911e-69629caf5cda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts\n",
            "Train score: 1.0 ; Validation score: 0.88\n",
            "\n",
            "Unigram Tf-Idf\n",
            "Train score: 0.95 ; Validation score: 0.89\n",
            "\n",
            "Bigram Counts\n",
            "Train score: 1.0 ; Validation score: 0.9\n",
            "\n",
            "Bigram Tf-Idf\n",
            "Train score: 0.98 ; Validation score: 0.9\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_and_show_scores(X_train_unigram, y_train, 'Unigram Counts')\n",
        "train_and_show_scores(X_train_unigram_tf_idf, y_train, 'Unigram Tf-Idf')\n",
        "train_and_show_scores(X_train_bigram, y_train, 'Bigram Counts')\n",
        "train_and_show_scores(X_train_bigram_tf_idf, y_train, 'Bigram Tf-Idf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTJL0kfNKaVo"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;The best data form seems to be **bigram with tf-idf** as it gets the highest validation accuracy: **0.9**; we will use it next for hyper-parameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "3POYbQOEKaVp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "nSWXRzlRKaVp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZAytCKSKaVp"
      },
      "source": [
        "<h1> TUTORIAL </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd5KL04gKaVp"
      },
      "source": [
        "<h2>Using the processed twitter data from yesterday's challenge</h2>.\n",
        "\n",
        "\n",
        "- Form a new data frame (named `cleanTweet`), containing columns $\\textbf{clean-text}$ and $\\textbf{polarity}$.\n",
        "\n",
        "- Write a function `text_category` that takes a value `p` and returns, depending on the value of p, a string `'positive'`, `'negative'` or `'neutral'`.\n",
        "\n",
        "- Apply this function (`text_category`) on the $\\textbf{polarity}$ column of `cleanTweet` in 1 above to form a new column called $\\textbf{score}$ in `cleanTweet`.\n",
        "\n",
        "- Visualize The $\\textbf{score}$ column using piechart and barchart\n",
        "\n",
        "<h5>Now we want to build a classification model on the clean tweet following the steps below:</h5>\n",
        "\n",
        "* Remove rows from `cleanTweet` where $\\textbf{polarity}$ $= 0$ (i.e where $\\textbf{score}$ = Neutral) and reset the frame index.\n",
        "* Construct a column $\\textbf{scoremap}$ Use the mapping {'positive':1, 'negative':0} on the $\\textbf{score}$ column\n",
        "* Create feature and target variables `(X,y)` from $\\textbf{clean-text}$ and $\\textbf{scoremap}$ columns respectively.\n",
        "* Use `train_test_split` function to construct `(X_train, y_train)` and `(X_test, y_test)` from `(X,y)`\n",
        "\n",
        "* Build an `SGDClassifier` model from the vectorize train text data. Use `CountVectorizer()` with a $\\textit{trigram}$ parameter.\n",
        "\n",
        "* Evaluate your model on the test data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ddHUmsBIKaVp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "5ksvJ_EwKaVp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "VoyJWI-OKaVp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XoZt2mvKaVp"
      },
      "source": [
        "# EXTENSION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnsKx1goKaVp"
      },
      "source": [
        "### Using Cross-Validation for hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDTdxL5oKaVp"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;For this part we will use `RandomizedSearchCV`<sup>(12)</sup> which chooses the parameters randomly from the list that we give, or according to the distribution that we specify from `scipy.stats` (e.g. uniform); then is estimates the test error by doing cross-validation and after all iterations we can find the best estimator, the best parameters and the best score in the variables `best_estimator_`, `best_params_` and `best_score_`.  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;Because the search space for the parameters that we want to test is very big and it may need a huge number of iterations until it finds the best combination, we will split the set of parameters in 2 and do the hyper-parameter tuning process in two phases. First we will find the optimal combination of loss, learning_rate and eta0 (i.e. initial learning rate); and then for penalty and alpha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "pY8wqSk7KaVq"
      },
      "outputs": [],
      "source": [
        "X_train = X_train_bigram_tf_idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Bog27e0KaVq"
      },
      "source": [
        "#### Phase 1: loss, learning rate and initial learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "eGY3A1GtKaVq"
      },
      "outputs": [],
      "source": [
        "clf = SGDClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "WXQvAGhqKaVq"
      },
      "outputs": [],
      "source": [
        "distributions = dict(\n",
        "    loss=['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
        "    learning_rate=['optimal', 'invscaling', 'adaptive'],\n",
        "    eta0=uniform(loc=1e-7, scale=1e-2)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "SbWfzec5KaVq",
        "outputId": "e17924c5-542b-4036-d923-589d0fff474e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'eta0': 0.001175586099480908, 'learning_rate': 'optimal', 'loss': 'modified_huber'}\n",
            "Best score: 0.9043599999999999\n"
          ]
        }
      ],
      "source": [
        "random_search_cv = RandomizedSearchCV(\n",
        "    estimator=clf,\n",
        "    param_distributions=distributions,\n",
        "    cv=5,\n",
        "    n_iter=50\n",
        ")\n",
        "random_search_cv.fit(X_train, y_train)\n",
        "print(f'Best params: {random_search_cv.best_params_}')\n",
        "print(f'Best score: {random_search_cv.best_score_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUoQAZgcKaVq"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;Because we got \"learning_rate = optimal\" to be the best, then we will ignore the eta0 (initial learning rate) as it isn't used when learning_rate='optimal'; we got this value of eta0 just because of the randomness involved in the process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VqHqah1KaVq"
      },
      "source": [
        "#### Phase 2: penalty and alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wD_p2MHKaVq"
      },
      "outputs": [],
      "source": [
        "clf = SGDClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkxfZ4iFKaVr"
      },
      "outputs": [],
      "source": [
        "distributions = dict(\n",
        "    penalty=['l1', 'l2', 'elasticnet'],\n",
        "    alpha=uniform(loc=1e-6, scale=1e-4)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln43aidgKaVr"
      },
      "outputs": [],
      "source": [
        "random_search_cv = RandomizedSearchCV(\n",
        "    estimator=clf,\n",
        "    param_distributions=distributions,\n",
        "    cv=5,\n",
        "    n_iter=50\n",
        ")\n",
        "random_search_cv.fit(X_train, y_train)\n",
        "print(f'Best params: {random_search_cv.best_params_}')\n",
        "print(f'Best score: {random_search_cv.best_score_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRq_fh3_KaVr"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;So, the best parameters that I got are:  \n",
        "`loss: squared_hinge  \n",
        " learning_rate: optimal  \n",
        " penalty: l2  \n",
        " alpha: 1.2101013664295101e-05  `"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjgQOtTYKaVr"
      },
      "source": [
        "#### Saving the best classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "gE89zdMQKaVr",
        "outputId": "87980aa3-a95d-4267-eaeb-f66200415c07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['classifiers/sgd_classifier.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "sgd_classifier = random_search_cv.best_estimator_\n",
        "\n",
        "dump(random_search_cv.best_estimator_, 'classifiers/sgd_classifier.joblib')\n",
        "\n",
        "# sgd_classifier = load('classifiers/sgd_classifier.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLmbQmqFKaVr"
      },
      "source": [
        "### Testing model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "1ZanvxrZKaVr"
      },
      "outputs": [],
      "source": [
        "X_test = bigram_vectorizer.transform(imdb_test['text'].values)\n",
        "X_test = bigram_tf_idf_transformer.transform(X_test)\n",
        "y_test = imdb_test['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "AHsMlCuTKaVr",
        "outputId": "864c7b75-7ff2-462c-d799-1fd09fde37ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9014\n"
          ]
        }
      ],
      "source": [
        "score = sgd_classifier.score(X_test, y_test)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2FyK0gtKaVr"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;And we got **90.18%** test accuracy. That's not bad for our simple linear model. There are more advanced methods that give better results. The current state-of-the-art on this dataset is **97.42%** <sup>(13)</sup>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUADq1qjKaVr"
      },
      "source": [
        "# Deployment\n",
        "* Flask\n",
        "* Streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrXxKVFWKaVr"
      },
      "source": [
        "# References\n",
        "\n",
        "<sup>(1)</sup> &nbsp;[Sentiment Analysis - Wikipedia](https://en.wikipedia.org/wiki/Sentiment_analysis)  \n",
        "<sup>(2)</sup> &nbsp;[Learning Word Vectors for Sentiment Analysis](http://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf)  \n",
        "<sup>(3)</sup> &nbsp;[Bag-of-words model - Wikipedia](https://en.wikipedia.org/wiki/Bag-of-words_model)  \n",
        "<sup>(4)</sup> &nbsp;[Tf-idf - Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)  \n",
        "<sup>(5)</sup> &nbsp;[TfidfTransformer - Scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)  \n",
        "<sup>(6)</sup> &nbsp;[Stop words - Wikipedia](https://en.wikipedia.org/wiki/Stop_words)  \n",
        "<sup>(7)</sup> &nbsp;[A list of English stopwords](https://gist.github.com/sebleier/554280)  \n",
        "<sup>(8)</sup> &nbsp;[CountVectorizer - Scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)  \n",
        "<sup>(9)</sup> &nbsp;[Scipy sparse matrices](https://docs.scipy.org/doc/scipy/reference/sparse.html)  \n",
        "<sup>(10)</sup> [Compressed Sparse Row matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix)  \n",
        "<sup>(11)</sup> [SGDClassifier - Scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)  \n",
        "<sup>(12)</sup> [RandomizedSearchCV - Scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)  \n",
        "<sup>(13)</sup> [Sentiment Classification using Document Embeddings trained with\n",
        "Cosine Similarity](https://www.aclweb.org/anthology/P19-2057.pdf)  "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "sentiment-analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}